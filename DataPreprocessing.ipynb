{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e79c8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install all the required packages and run the required libraries\n",
    "##-----------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimpy import clean_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a3c0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of Functions\n",
    "##-----------------------------------------------\n",
    "#write to CSV file\n",
    "#writeCSV(table DataSet, String file):The writeCSV function writes the dataframe to a CSV file.\n",
    "#Arguments: DataSet is the name of dataframe to save, file is the name of the CSV output file.\n",
    "#Returns a CSV file\n",
    "def writeCSV(dataset,filename):\n",
    "     dataset.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a65c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read a CSV file\n",
    "#readCSV(String file):The readCSV function reads the CSV file into workplace\n",
    "#Arguments: file is the CSV file in the select work directory.\n",
    "def readCSV(filename):\n",
    "    csv_data = pd.read_csv(filename)\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2973af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select dataset columns for analysis\n",
    "#selectColumns(table DataSet, string columnName, …): This function selects/keeps the list columns needed for analysis from the dataset. Only the\n",
    "#list of selected columns/attributes are included in the dataset. \n",
    "#Arguments: DataSet is the name of the dataframe, columnName is the name of the column to keep in the dataset. Many can be listed, separated by commas.\n",
    "#Returns a dataset including only the list of columns/attributes that are selected\n",
    "def selectColumns(dataset,selectCol):\n",
    "    return dataset[selectCol]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "837db080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete columns from the dataset\n",
    "def deleteColumns(dataset,deleteCol):\n",
    "    return dataset.drop(columns=deleteCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22237f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean column headers\n",
    "#cleanHeaders(table DataSet)\n",
    "#This function cleans the headers of the columns from spaces and other special characters.\n",
    "#It only keeps lower case letters, numbers, and underscores (_). The spaces are replaced by ‘_’ and the special characters are removed. \n",
    "#Returns a dataframe with clean header names\n",
    "def cleanHeaders(dataset):\n",
    "    return clean_columns(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a66018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter rows\n",
    "#The filter function keeps records/rows based on the conditions specified. \n",
    "#Only the rows where the condition is TRUE are kept in the DataSet. \n",
    "#The filter function supports multiple functions, for example: ==, >, <, >=, <=, &, | , ! . \n",
    "def filterRows(dataset,conditions):\n",
    "    return dataset.query(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ee462b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove rows with low frequency\n",
    "#Column represents the column you want to filter\n",
    "# freq the threshold value that is used to filter out rows whose count is less than freq.\n",
    "def removeEventsLowFrequency(dataset,Column,freq):\n",
    "    return dataset[dataset.groupby(Column)[Column].transform('count').ge(freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a17336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete traces with number of events less than a specific number (num)\n",
    "def deleteTracesLengthLessThan(dataset,Column,freq):\n",
    "    return dataset[dataset.groupby(Column)[Column].transform('count').ge(freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ba39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete traces that do not start with a specific start event\n",
    "def deleteTruncatedTracesStart(dataset,Column,startStr):\n",
    "    return dataset.loc[data[Column].str.startswith(startStr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete traces that do not start with a specific end event\n",
    "def deleteTruncatedTracesStart(dataset,Column,startStr):\n",
    "    return dataset.loc[data[Column].str.endswith(startStr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cea553fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete traces with total duration less than t\n",
    "def deleteTracesWithTimeLess(dataset,company_id,time,t):\n",
    "    dataset['new_time']=pd.to_datetime(dataset[time],format=\"%d/%m/%Y %H:%M\")\n",
    "    dataset['new_time']=(dataset['new_time'].dt.hour*60+dataset['new_time'].dt.minute)*60 + dataset['new_time'].dt.second\n",
    "    dataset=dataset.sort_values(by=[company_id,'new_time'])\n",
    "    result=dataset.groupby(company_id).filter(lambda oneCompanyData: (oneCompanyData.iloc[-1].new_time - oneCompanyData.iloc[0].new_time) > t)\n",
    "    result=deleteColumns(dataset,'new_time')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8d44d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate two columns\n",
    "\n",
    "# data[\"test\"] = data[\"event\"].astype(str) + data[\"theme\"].astype(str)\n",
    "\n",
    "def concatenateColumns(dataset,newCol,*cols):\n",
    "    dataset[newCol]=\"\"\n",
    "    for col in cols:\n",
    "        dataset[newCol]=dataset[newCol]+\" \"+dataset[col].astype(str)\n",
    "    return  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8535014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eventIsRepeated(dataset,event):\n",
    "    dataset['isRepeated']=data.duplicated(subset=[event],keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep first event\n",
    "def keepFirstEvent(dataset,time,event):\n",
    "    return dataset.sort_values(by=time).drop_duplicates(subset=[event])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb1a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep last event\n",
    "def keepLastEvent(dataset,time,event):\n",
    "    return dataset.sort_values(by=time,asending=false).drop_duplicates(subset=[event]).sort_values(by=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5bf27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all events\n",
    "def deleteAllEvents(dataset,event,eventName):\n",
    "    return dataset.drop(dataset[dataset.event==eventName].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b419b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge rows\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
